batch: 0
Loss: 6.935507297515869
batch: 1
Loss: 6.9424662590026855
batch: 2
Loss: 6.943796634674072
batch: 3
Loss: 6.947473526000977
batch: 4
Loss: 6.932703971862793
batch: 5
Loss: 6.948572158813477
Traceback (most recent call last):
  File "main.py", line 75, in <module>
    print(device)
  File "main.py", line 54, in main
    ResNet = train(
  File "C:\Users\jthan\OneDrive\Desktop\2024\Projects\Bird_API\src\train.py", line 36, in train
    optimizer.step()
  File "C:\Users\jthan\anaconda3\envs\cs7643-a4\lib\site-packages\torch\_tensor.py", line 521, in backward
    torch.autograd.backward(
  File "C:\Users\jthan\anaconda3\envs\cs7643-a4\lib\site-packages\torch\autograd\__init__.py", line 289, in backward
    _engine_run_backward(
  File "C:\Users\jthan\anaconda3\envs\cs7643-a4\lib\site-packages\torch\autograd\graph.py", line 769, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
  File "C:\Users\jthan\anaconda3\envs\cs7643-a4\lib\site-packages\wandb\integration\torch\wandb_torch.py", line 276, in <lambda>
    handle = var.register_hook(lambda grad: _callback(grad, log_track))
KeyboardInterrupt
Traceback (most recent call last):
  File "main.py", line 75, in <module>
    print(device)
  File "main.py", line 54, in main
    ResNet = train(
  File "C:\Users\jthan\OneDrive\Desktop\2024\Projects\Bird_API\src\train.py", line 36, in train
    optimizer.step()
  File "C:\Users\jthan\anaconda3\envs\cs7643-a4\lib\site-packages\torch\_tensor.py", line 521, in backward
    torch.autograd.backward(
  File "C:\Users\jthan\anaconda3\envs\cs7643-a4\lib\site-packages\torch\autograd\__init__.py", line 289, in backward
    _engine_run_backward(
  File "C:\Users\jthan\anaconda3\envs\cs7643-a4\lib\site-packages\torch\autograd\graph.py", line 769, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
  File "C:\Users\jthan\anaconda3\envs\cs7643-a4\lib\site-packages\wandb\integration\torch\wandb_torch.py", line 276, in <lambda>
    handle = var.register_hook(lambda grad: _callback(grad, log_track))
KeyboardInterrupt
